{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble  import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\")\n",
    "messages = messages.loc[:,['v1','v2']]\n",
    "messages.columns = [\"label\", \"message\"]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing Data and appending in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=2500)\n",
    "X_Bow = cv.fit_transform(corpus).toarray()\n",
    "X_Bow = pd.DataFrame(X_Bow, columns = cv.get_feature_names() )\n",
    "y_Bow = pd.get_dummies(messages['label'])\n",
    "y_Bow = y_Bow.loc[:,['spam']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the TFIDF of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(max_features=2500)\n",
    "X_TFIDF = tv.fit_transform(corpus).toarray()\n",
    "X_TFIDF = pd.DataFrame(X_TFIDF, columns = tv.get_feature_names() )\n",
    "y_TFIDF = pd.get_dummies(messages['label'])\n",
    "y_TFIDF = y_TFIDF.loc[:,['spam']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_hyperparameter_tuning(X,y):\n",
    "    model_params = {\n",
    "\n",
    "        'Logistic_Regression' : {\n",
    "            'model': LogisticRegression(solver='liblinear'),\n",
    "            'params': {\n",
    "                'C': list(range(1,5))\n",
    "            }\n",
    "         },  \n",
    "        'naive_bayes_gaussian': {\n",
    "           'model': GaussianNB(),\n",
    "           'params': {}\n",
    "         },\n",
    "        'naive_bayes_multinomial': {\n",
    "           'model': MultinomialNB(),\n",
    "           'params': {}\n",
    "         },\n",
    "        'Random_Forest': {\n",
    "            'model': RandomForestClassifier(),\n",
    "            'params' : {\n",
    "                'n_estimators': list(range(1,25))\n",
    "            }\n",
    "        },\n",
    "        'Decision_Tree': {\n",
    "            'model': DecisionTreeClassifier(),\n",
    "            'params': {\n",
    "                'criterion': ['gini','entropy'],  \n",
    "                'splitter' : ['best','random'],\n",
    "                'min_samples_leaf' : list(range(1,25))\n",
    "            }\n",
    "        },\n",
    "        'SVM': {\n",
    "            'model': svm.SVC(gamma='auto'),\n",
    "            'params' : {\n",
    "                'C': list(range(1,10)),\n",
    "                'kernel': ['rbf','linear']\n",
    "            }  \n",
    "        },\n",
    "        'XG_Boost': {\n",
    "            'model': XGBClassifier(silent=True, verbosity = 0),\n",
    "            'params': { 'n_estimators' :  [10, 50, 100, 130], \n",
    "                        'criterion': ['gini', 'entropy'], \n",
    "                        'max_depth': range(2, 10, 1) }\n",
    "            }  \n",
    "    }\n",
    "    scores = []\n",
    "\n",
    "    for model_name, mp in model_params.items():\n",
    "        print('Running ' + model_name)\n",
    "        clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "        clf.fit(X, y)\n",
    "        scores.append({\n",
    "            'model': model_name,\n",
    "            'best_score': clf.best_score_,\n",
    "            'best_params': clf.best_params_,\n",
    "            'best_estimators' : clf.best_estimator_\n",
    "        })\n",
    "    hyperparameter_tuning_results = pd.DataFrame(scores,columns=['model','best_score','best_params','best_estimators'])\n",
    "    return hyperparameter_tuning_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_Results = model_hyperparameter_tuning(X_Bow,y_Bow)\n",
    "BOW_Results['Method'] = 'Bag of words'\n",
    "BOW_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Results = model_hyperparameter_tuning(X_TFIDF,y_TFIDF) \n",
    "TFIDF_Results['Method'] = 'TFIDF'\n",
    "TFIDF_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_results = pd.concat([BOW_Results,TFIDF_Results])\n",
    "Combined_results.sort_values(by = 'best_score', inplace = True, ascending = False)\n",
    "Combined_results = Combined_results.reset_index(drop = True)\n",
    "\n",
    "best_estimator  = Combined_results.loc[0,'best_estimators']\n",
    "method = Combined_results.loc[0,'Method']\n",
    "print(\"Best Estimator : {}\".format(best_estimator))\n",
    "print(\"Best Method : {}\".format(method))\n",
    "Combined_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'TFIDF':\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_TFIDF, y_TFIDF, test_size=0.33, random_state=42)\n",
    "else:\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_Bow, y_Bow, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using best estimater on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator.fit(X_train, y_train)\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "if len(y_test['spam'].unique()) == 1:\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "else:\n",
    "    score = roc_auc_score(y_test, y_pred) \n",
    "\n",
    "print('Accuracy : {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted');ax.set_ylabel('Actual'); \n",
    "ax.set_title('Confusion matrix'); \n",
    "ax.xaxis.set_ticklabels(labels,rotation = 90); \n",
    "ax.yaxis.set_ticklabels(labels,rotation = 0);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
